---
title: Continuous Delivery
date: 2018-08-13 09:58:27
tags:
    - Project Management
---

# 《持续交付-发布可靠软件的系统方法》

===================== **基础** ===============================

## Part 1 基础篇

### 软件交付的问题

**关键词**：
部署流水线：构建 => 部署 => 测试 => 发布
自动化、持续集成

**发布反模式**
1. 手工部署
2. 开发完成之后才向类生产环境部署
3. 生产环境的手工配置管理

**关键词**：短周期【决定变更～用户可用】、高质量【质量不等于完美】
反馈：
1. 无论什么样的修改都应该触发反馈流程
2. 反馈应该尽快发出
3. 交付团队必须接受反馈，并依据它做出相应的行动

可工作的软件组成：可执行的代码、配置信息、运行环境、数据

**软件交付原则**
1. 为软件发布创建一个**可重复**且**可靠**的过程
	1. 尽可能地自动化
	2. 尽可能将所有东西纳入版本控制
2. 内建质量：尽早发现问题，解决问题，提前并频繁地做让你感到痛苦的事
3. DONE意味着“已发布”
4. 交付过程事每个成员的责任
5. 持续改进: 计划plan => 做do => 研究stydy => 行动act


## Part 2 配置管理

### 定义
**配置管理**：配置管理是指一个过程，通过该过程，所有与项目相关的产物，以及它们之间的关系都被**唯一**定义、修改、存储和检索

### 版本控制
**版本控制系统**：也称源代码控制管理系统或修订控制系统，是保存文件多个版本的一种机制。example：SCCS、RCS、CVS、Subversion、Mercurial、Git...

**版本控制的目的**
1. 保留每个文件的所有版本的历史信息，并使之易于查找
2. 让分布式团队可以愉快地协作

#### 与项目相关的所有东西都纳入版本控制
**目标**：能够随时获取软件在整个生命周期中任意时间点的文件状态【编译后的二进制代码不需要】

#### 频繁提交
1. 只有频繁提交代码，才能享受版本控制带来的好处
2. 一旦将代码提交，团队的所有人都能看到这些变更
3. 一次提交出发一次构建集成

提交需要确保不破坏原有系统：
1. 提交代码前运行测试套件
2. 增量式引入变化

当进行某项复杂的工作时，如何保证频繁提交的同时又不破坏原有系统？

**不推荐开分支的原因**
1. 违背了持续集成的宗旨，新分支推迟了新功能的整合，只有到分支被合并时才能发现集成问题
2. 多个开发者分别创建分支，问题会程指数增加，合并过程也会极其复杂
3. 尽管又好用的自动合并功能，但它无法解决语义冲突
4. 合并困难导致重构代码库变得困难

我们推荐使用**增量方式**开发新功能，并频繁且有规律地向版本控制系统提交代码。

#### 提交注释
推荐的提交注释：第一段简短地总结性描述；接下来描述更多细节；包含一个可以链接到项目管理工具中的一个功能或缺陷的链接

### 依赖管理
1. 外部库文件
2. 组件管理

### 软件配置管理
配置反模式：终级配置，系统配置工作变得非常复杂以至于抵消了其在灵活性上带来的好处
**更好的方式**：先专注于提供具有高价值且可配置程度较低的功能，然后在真正需要时再添加可配置选项

#### 配置分类
1. 构建时
2. 打包时
3. 部署软件程序时
4. 启动／运行时
建议：在相邻的两次部署之间，任何变更都应该作为配置项被捕获和记录，而不应该在编译或打包时植入

#### 应用程序配置管理
特定于测试环境或生产环境的实际配置信息应该与源代码分离在单独的代码库中。需要保证配置信息的版本与相应的应用软件的版本相匹配。

1. 获取配置信息
	1. 中央服务系统提供配置信息
	2. 中心仓库获取配置信息
2. 配置项建模
3. 系统配置测试
	1. 保证配置设置中对外部服务的饮用是良好的
	2. 冒烟测试

**跨应用配置管理**：配置选项索引表、实时存取配置信息

#### 管理配置信息的原则
将应用程序的配置信息当作代码一样来看待 
1. 明确配置注入时机
2. 配置项与代码同一个仓库保存，但配置值单独保存
3. 自动化
4. 容易查看
5. 明确命名
6. 模块化 and 封闭
7. DRY 原则
8. 最少化
9. 避免过度设计，应尽可能简单
10. 测试

### 环境管理
**环境**：应用程序所以来的硬件、软件、基础设施和外部系统
**原则**：环境的配置和应用程序的配置同样重要
**内容**
1. 操作系统，包括其版本、补丁级别以及配置设置
2. 软件包，及软件包的具体版本和配置
3. 网络拓扑结构
4. 外部服务，及其版本和配置信息
5. 现有的数据及其他信息
**高效管理环境策略原则**
1. 二进制文件与配置信息分离
2. 配置信息保存在一处


## Part 3 持续集成
**要求**：每当有人提交代码时，就对整个应用进行构建，并对其执行全面的自动化测试集合
**目标**：让正在开发的软件一直处于可工作状态

### 实现持续集成
1. 准备工作
	1. 版本控制
	2. 自动化构建【命令行构建的重要性】
	3. 团队共识
2. 持续集成工具
	1. 知道那里寻找代码控制库
	2. 运行什么脚本进行编译&自动化测试
	3. 如果提交破坏了程序，应该如何提醒 
3. 基本的持续集成过程
	1. 确认上一次提交构建已成功
	2. 更新代码到本地
	3. 本地运行构建&测试，并确认能成功
	4. 提交代码到版本库
	5. 确认本次提交构建成功

### 持续集成的前提条件
1. 频繁提交【小步修改】
2. 全面的自动化测试套件：单元测试、组件测试、验收测试
3. 较短的构建和测试过程
4. 开发环境管理

### 持续集成软件
**基本功能**：轮询版本控制系统、可视化

### 必须的实践
1. 构建失败之后不要提交新代码
2. 提交前在本地运行所有的提交测试，或者让持续集成服务器完成此事
3. 等提交测试通过后再继续工作
4. 回家之前，构建必须处于成功状态
5. 时刻准备着回滚到前一个版本
6. 回滚之前要规定一个修复时间
7. 不要将失败的测试注释掉
8. 为自己导致的问题负责
9. 测试驱动开发 TDD

### 推荐的实践
1. 极限编程【持续集成是极限编程的十二个核心实践之一】：TTD、代码集体所有权、重构...
2. 若违背架构原则，就让构建失败
3. 若测试运行变慢，就让构建失败
4. 若有编译警告或代码风格问题，就让测试失败

### 分布式团队 61~66


## Part 4 测试策略 

推荐阅读：《Agile Testing》

测试策略的设计主要是**识别**和**评估**项目风险的优先级，以及决定采用哪些行动来缓解风险的一个过程。

关键在于**建立最短反馈环**，于是**自动化测试**成为关键，但还需要结合手工测试

### 测试分类

测试象限 P68 图4-1

两个维度：
1. 业务导向 or 技术导向
2. 支持开发过程 or 评判项目

#### 业务导向 and 支持开发过程
1. 功能测试／验收测试
**目的**：确保用户故事的验收条件得到满足
**范围**：功能、容量、易用性、安全性、可变性、可用性
**分析**：Happy Path & Alternate Path & Sad Path、等价划分分析 & 边界值分析
**环境**：类生产环境【尽可能保证和生产环境相似】
**外部服务**：模拟[mock]技术
**自动化验收测试**
- 加快反馈速度
- 减少测试人员负担
- 回归测试 
- 需求文档

#### 技术导向 and 支持开发过程
1. 单元测试
**目的**：单独测试一个特定的代码段
**范围**：不包括数据库、文件系统、外部系统，不包括组件之间的交互，覆盖每个代码分支路径
2. 组件测试
**目的**：测试相对更大的功能集合
**范围**：需要连接数据库、文件系统或其他系统
3. 部署测试
**目的**：检查部署过程是否正常，即应用程序是否被正确的安装、配置，是否能与所需的服务正常通信，并得到回应

#### 业务导向 and 评价项目
1. 手工测试
**目的**：验证我们实际交付给用户的应用软件是否符合其期望
**方式**：演示(迭代完成时)
2. 探索性测试
**目的**：覆盖新需求
3. 易用性测试
**目的**：验证用户是否能很容易的使用该应用完成工作
**方式**：情景调查
4. Beta 测试：让真正用户使用

#### 技术导向 and 评价项目
1. 功能测试
2. 非功能测试
**目的**：测试功能之外的系统其它方面质量的测试，如容量、可用性、安全性

#### 测试替身
自动化测试中，运行时用一个模拟对象来代替系统中的一部分，以便于被测试的那部分和系统其它部分的交互被严格地掌控，从而更容易确定这一特定部分的行为。
1. 哑对象 dummy object 被传递但不真正被使用的对象，常作为填充参数
2. 假对象 fake object 可以真正使用，但是通常会利用捷径，不适合在生产环境使用，如内存数据库
3. 桩 stub 为每个调用提供一个封装好的响应，只用于测试
4. spy 一种科技路一些关于它们如何被调用的信息的桩
5. 模拟对象 mock 在编程时就设定了它预期要接受的调用

### 实践

#### 新项目
流程定义：
1. 客户、分析师、测试人员定义验收条件
2. 测试和开发人员一起基于验收条件实现验收测试的自动化
3. 开发人员编码来满足验收条件
4. 自动化测试失败，开发人员应该把它定位高优先级并修复它

#### 项目进行中
选取应用程序中那些最常见、最重要且高价值的用例为起点。进行所有 Happy Path 的测试。

#### 遗留系统
1. 覆盖核心功能的冒烟测试
2. 自动化测试分层
3. 只写有价值的自动化测试

#### 集成测试
1. 隔离
2. 测试用具

### 流程
管理待修复缺陷列表
1. 可视化
2. 向对待功能特性一样来对待缺陷
3. 缺陷分级：严重、阻塞、中、低

=================== **部署流水线** ======================

## Part 5 部署流水线解析

**部署流水线**是指软件从版本控制库到用户手中这一过程的自动化表现形式。

1. 提交阶段：从技术角度上断言整个系统是可以工作的；工作内容包括**编译**、**单元级别自动化测试**、**代码分析**
2. 自动化验收测试阶段：从功能和非功能角度断言整个系统是可以工作的，即从系统行为看，它满足用户的需要且符合客户的需求规范
3. 手工测试阶段：断言系统是可用的，满足系统要求，试图发现自动化测试未能捕获的缺陷，并验证是否为用户提供了价值；工作内容包括**探索性测试**、**集成环境测试**、**UAT测试**
4. 发布阶段：将软件交付给用户

### 实践建议

1. 只生成一次二进制包【提交阶段】
原因：避免引入编译结果不一致的风险，并且节省编译时间
2. 对不同环境采用同一部署方式
原因：避免部署方式区别导致的部署失败
3. 对部署进行冒烟测试
4. 向生产环境的副本中部署
5. 每次变更都要立即在流水线中传递
6. 只要有环节失败，就停止整个流水线

#### 提交阶段

1. 编译代码
2. 运行一套提交测试
3. 为后续阶段创建二进制包
4. 执行代码分析来检查弟阿玛的健康状况
5. 为后续阶段做准备工作，如准备测试数据库

**一些代码健康度量**：

- 测试覆盖率
- 重复代码数量
- 圈复杂度
- 输入耦合度 and 输出耦合度
- 编译警告数量
- 代码风格

#### 测试阶段

1. 自动化验收测试
2. 其它

#### 发布准备

